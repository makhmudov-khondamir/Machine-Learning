{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOG1pvU98LRHYweU2omMWJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makhmudov-khondamir/Machine-Learning-Projects/blob/main/Project%3A%20Airfare%20price%20prediction(Updated).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Airfare price prediction(Updated)**\n",
        "Predicting what the future prices of airline tickets might be for airlines"
      ],
      "metadata": {
        "id": "gQiB-AVsmG40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#extract the zip file and dataset preparation\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# path to the zip file\n",
        "zip_path = 'aviachipta-narxini-bashorat-qilish.zip'\n",
        "\n",
        "# directory for extraction\n",
        "new_file_name = '/content/extracted_files'\n",
        "\n",
        "# create the directory if it does not exist\n",
        "os.makedirs(new_file_name, exist_ok=True)\n",
        "\n",
        "# and extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(new_file_name)"
      ],
      "metadata": {
        "id": "YcuwBA7jXdRW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import plotly.express as px\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "s_iGPtgJXern"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/extracted_files/train_data.csv\")\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "\n",
        "x = df.drop('price', axis=1)\n",
        "y = df['price']\n",
        "\n",
        "categorical = list(x.select_dtypes(include=['object']).columns)\n",
        "numerical = list(x.select_dtypes(include=['number']).columns)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipelineCat = Pipeline([\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "pipelineNum = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "fullpipeline = ColumnTransformer([\n",
        "    ('categorical', pipelineCat, categorical),\n",
        "    ('numerical', pipelineNum, numerical)\n",
        "])\n",
        "\n",
        "Xtrain = fullpipeline.fit_transform(x_train)\n",
        "Xtest = fullpipeline.transform(x_test)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "model = XGBRegressor(random_state=42)\n",
        "\n",
        "cv_scores = cross_val_score(model, Xtrain, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
        "mean_cv_score = -cv_scores.mean()\n",
        "print(f'Cross-Validation Mean RMSE: {np.sqrt(mean_cv_score)}')\n",
        "\n",
        "model.fit(Xtrain, y_train)\n",
        "\n",
        "predictionRF = model.predict(Xtest)\n",
        "\n",
        "mseRF = mean_squared_error(y_test, predictionRF)\n",
        "rmseRF = np.sqrt(mseRF)\n",
        "print(f'Test RMSE: {rmseRF}')\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(XGBRegressor(random_state=42), param_grid, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
        "grid_search.fit(Xtrain, y_train)\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict with the best model\n",
        "best_predictions = best_model.predict(Xtest)\n",
        "best_mse = mean_squared_error(y_test, best_predictions)\n",
        "best_rmse = np.sqrt(best_mse)\n",
        "\n",
        "print(f'Best Model RMSE: {best_rmse}')\n",
        "print(f'Best Hyperparameters: {best_params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxwRzgX5XFkK",
        "outputId": "6ed5cbb9-8e34-46b0-b23e-3e2922efa32d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Mean RMSE: 3875.95521670487\n",
            "Test RMSE: 3771.454832186972\n",
            "Best Model RMSE: 3555.9087616560564\n",
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "hSrHIoYKlqAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set=pd.read_csv(\"/content/extracted_files/test_data.csv\")\n",
        "test_set\n",
        "\n",
        "preparedX=fullpipeline.transform(test_set)\n",
        "prediction=best_model.predict(preparedX)\n",
        "\n",
        "sol=pd.DataFrame({'id':test_set['id'],'price':prediction})\n",
        "\n",
        "sol.to_csv('sol.csv',index=False)"
      ],
      "metadata": {
        "id": "6wkjibVqkv8b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0yDocuxCmEpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}