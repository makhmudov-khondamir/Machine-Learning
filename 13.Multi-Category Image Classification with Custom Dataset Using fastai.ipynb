{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNv4SlY/uAjtO9rMDk7MaxS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makhmudov-khondamir/Machine-Learning-Projects/blob/main/13.Multi-Category%20Image%20Classification%20with%20Custom%20Dataset%20Using%20fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Title: Multi-Category Image Classification with Custom Dataset Using fastai**\n",
        "\n",
        "### Description:\n",
        "This project demonstrates how to build and train an image classification model for multiple categories using the fastai library. The example uses a custom dataset from the Open Images Dataset (OIDv4) to classify images into different transport categories.\n",
        "\n",
        "### Dataset:\n",
        "The dataset used in this project is a subset of the Open Images Dataset (OIDv4), which contains images categorized into various classes. In this example, we use categories related to different types of transport."
      ],
      "metadata": {
        "id": "dKYNS8ipLsH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import fastai\n",
        "\n",
        "# Dataset. We use Google's Open Images Dataset v4 to download the dataset.  This dataset consists of 600 classes and contains 1.7 million images.\n",
        "# We use OIDv4_Toolkit to download these images.  (https://github.com/EscVM/OIDv4_ToolKi)\n",
        "! git clone https://github.com/EscVM/OIDv4_ToolKit.git\n",
        "\n",
        "# This installs the necessary Python packages (pandas,requests,tqdm,argparse,Pillow,numpy,sh..etc) listed in the requirements.txt file from the OIDv4 ToolKit.\n",
        "!cd OIDv4_ToolKit && pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "mE838nbK2rXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, we will build a model that can classify three types of vehicles (cars, airplanes, water transports (ships, boats)).  \n",
        "That's why we download 200 images for each class using OlDv4 Toolkit."
      ],
      "metadata": {
        "id": "z052zHWEBJ9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd OIDv4_ToolKit && python3 main.py downloader --Dataset /content --classes Car Airplane Boat --type_csv train --limit 200"
      ],
      "metadata": {
        "id": "DXsYg0pDBVR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building a Model**"
      ],
      "metadata": {
        "id": "7ViZcB5nBsaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "from ipywidgets import widgets\n",
        "\n",
        "path=Path('train')  # train is the directory containing those 200 training images for our project. It is located in Files\n",
        "path.ls() # *it shows these 3 files included\n",
        "\n",
        "fls=get_image_files(path)\n",
        "fls # *it shows these all images included\n",
        "\n",
        "failed=verify_images(path) # *Checks for corrupted image files in the specified directory.\n",
        "failed\n",
        "\n",
        "transports=DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(224)\n",
        ")\n",
        "\n",
        "# Dataloader\n",
        "dls=transports.dataloaders(path)\n",
        "\n",
        "#check\n",
        "dls.train.show_batch(max_n=8, nrows=2)\n",
        "\n",
        "learn=cnn_learner(dls,resnet34, metrics=accuracy)\n",
        "learn.fine_tune(4)\n",
        "\n",
        "interp=ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "\n",
        "interp.plot_top_losses(5, nrows=1)"
      ],
      "metadata": {
        "id": "46YNQhSuBGhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload=widgets.FileUpload()\n",
        "upload"
      ],
      "metadata": {
        "id": "HCy2-P5MVNPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=PILImage.create(upload.data[-1])\n",
        "pred, pred_id, prob=learn.predict(img)\n",
        "print(f'Prediction: {pred}')\n",
        "print(f'Probability: {prob[pred_id]}')\n",
        "img"
      ],
      "metadata": {
        "id": "u3cGp0XeVPP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Explanation:\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import fastai\n",
        "\n",
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git\n",
        "\n",
        "!cd OIDv4_ToolKit && pip install -r requirements.txt\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Cloning the OIDv4 ToolKit**:\n",
        "   - `!git clone https://github.com/EscVM/OIDv4_ToolKit.git`: This command clones the OIDv4 ToolKit repository, which provides tools to download images from the Open Images Dataset.\n",
        "\n",
        "2. **Installing Requirements**:\n",
        "   - `!cd OIDv4_ToolKit && pip install -r requirements.txt`: This installs the necessary Python packages listed in the `requirements.txt` file from the OIDv4 ToolKit.\n",
        "\n",
        "#### Real-Life Example:\n",
        "Think of this as downloading a tool from the internet to help you gather and organize images from a large online database.\n",
        "\n",
        "```python\n",
        "from fastai.vision.all import *\n",
        "from ipywidgets import widgets\n",
        "\n",
        "#path\n",
        "path=Path('train')\n",
        "path.ls()\n",
        "fls=get_image_files(path)\n",
        "fls\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Setting the Path**:\n",
        "   - `path = Path('train')`: Specifies the directory where the training images are stored.\n",
        "   - `path.ls()`: Lists all the files and directories in the 'train' directory.\n",
        "\n",
        "2. **Getting Image Files**:\n",
        "   - `fls = get_image_files(path)`: Retrieves all image file paths in the specified directory.\n",
        "\n",
        "#### Real-Life Example:\n",
        "Imagine you have a folder named 'train' that contains images of different types of transport. This step identifies all image files in that folder.\n",
        "\n",
        "```python\n",
        "failed = verify_images(path)\n",
        "failed\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Verifying Images**:\n",
        "   - `failed = verify_images(path)`: Checks for corrupted image files in the specified directory.\n",
        "   - `failed`: Lists any files that failed the verification check.\n",
        "\n",
        "#### Real-Life Example:\n",
        "Consider this step as a quality check to ensure all images in your folder are readable and not corrupted.\n",
        "\n",
        "```python\n",
        "transports = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(224)\n",
        ")\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Defining the DataBlock**:\n",
        "   - `blocks=(ImageBlock, CategoryBlock)`: Specifies the types of data: images and their categories.\n",
        "   - `get_items=get_image_files`: Function to get image files.\n",
        "   - `splitter=RandomSplitter(valid_pct=0.2, seed=42)`: Randomly splits the data into training and validation sets, with 20% for validation.\n",
        "   - `get_y=parent_label`: Uses the parent folder name as the label for each image.\n",
        "   - `item_tfms=Resize(224)`: Resizes all images to 224x224 pixels.\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# Dataloader\n",
        "dls = transports.dataloaders(path)\n",
        "\n",
        "#check\n",
        "dls.train.show_batch(max_n=8, nrows=2)\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Creating DataLoaders**:\n",
        "   - `dls = transports.dataloaders(path)`: Creates DataLoaders for the training and validation datasets.\n",
        "\n",
        "2. **Displaying a Batch of Images**:\n",
        "   - `dls.train.show_batch(max_n=8, nrows=2)`: Displays a batch of 8 training images in 2 rows.\n",
        "\n",
        "#### Real-Life Example:\n",
        "This step loads the images into memory for training and displays a sample batch to visually confirm the data and labels.\n",
        "\n",
        "```python\n",
        "learn = cnn_learner(dls, resnet34, metrics=accuracy)\n",
        "learn.fine_tune(4)\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Creating and Training the Model**:\n",
        "   - `cnn_learner(dls, resnet34, metrics=accuracy)`: Creates a Convolutional Neural Network (CNN) learner using the ResNet-34 architecture.\n",
        "   - `learn.fine_tune(4)`: Fine-tunes the model for 4 epochs.\n",
        "\n",
        "#### Real-Life Example:\n",
        "Think of this step as teaching a pre-trained neural network to recognize different types of transport using your dataset, refining its knowledge over 4 iterations.\n",
        "\n",
        "```python\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "\n",
        "interp.plot_top_losses(5, nrows=1)\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Interpreting the Model**:\n",
        "   - `ClassificationInterpretation.from_learner(learn)`: Creates an interpretation object for the trained model.\n",
        "   - `interp.plot_confusion_matrix()`: Plots the confusion matrix to visualize the model's performance.\n",
        "   - `interp.plot_top_losses(5, nrows=1)`: Displays the top 5 images where the model's predictions were most incorrect.\n",
        "\n",
        "#### Real-Life Example:\n",
        "Consider this step as analyzing the model's performance, identifying areas where it performs well and where it makes mistakes.\n",
        "\n",
        "```python\n",
        "upload = widgets.FileUpload()\n",
        "upload\n",
        "\n",
        "img = PILImage.create(upload.data[-1])\n",
        "pred, pred_id, prob = learn.predict(img)\n",
        "print(f'Prediction: {pred}')\n",
        "print(f'Probability: {prob[pred_id]}')\n",
        "img\n",
        "```\n",
        "\n",
        "#### What Happens in This Step:\n",
        "\n",
        "1. **Uploading and Predicting**:\n",
        "   - `upload = widgets.FileUpload()`: Creates a file upload widget.\n",
        "   - `img = PILImage.create(upload.data[-1])`: Creates an image object from the uploaded file.\n",
        "   - `pred, pred_id, prob = learn.predict(img)`: Uses the trained model to predict the category of the uploaded image.\n",
        "   - `print(f'Prediction: {pred}')`: Prints the predicted category.\n",
        "   - `print(f'Probability: {prob[pred_id]}')`: Prints the probability of the predicted category.\n",
        "\n",
        "\n",
        "This step allows you to upload a new image, have the model predict its category, and see the prediction and its probability."
      ],
      "metadata": {
        "id": "Xh0LU4FREmmm"
      }
    }
  ]
}